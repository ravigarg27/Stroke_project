{
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import os\n",
      "import cPickle as pickle\n",
      "from pprint import pprint\n",
      "from time import time\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from scipy import interp\n",
      "from itertools import cycle\n",
      "\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.metrics import classification_report, accuracy_score\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn.feature_selection import SelectFromModel\n",
      "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
      "from sklearn.preprocessing import label_binarize\n",
      "\n",
      "import xgboost as xgb\n",
      "from xgboost.sklearn import XGBClassifier\n",
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cross-validation with pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def crossValidation(n_folds, pipeline, X, y):\n",
      "    k_fold = StratifiedKFold(n_folds)\n",
      "    scores = []\n",
      "    for train_indices, test_indices in k_fold.split(X, y):\n",
      "        train_text = np.asarray(X[train_indices])\n",
      "        train_y    = np.asarray(y[train_indices])\n",
      "\n",
      "        test_text  = np.asarray(X[test_indices])\n",
      "        test_y = np.asarray(y[test_indices])\n",
      "        test_y_binarize = label_binarize(test_y, classes=[0,1,2,3,4])\n",
      "        \n",
      "        pipeline.fit(train_text, train_y)\n",
      "        vocab = pipeline.named_steps[\"vect\"].vocabulary_\n",
      "        selected_features = np.sum(pipeline.named_steps[\"f_select\"].get_support())\n",
      "        \n",
      "        \n",
      "        print \"Number of training samples \", train_text.shape[0]\n",
      "        print \"Number of validation samples \", test_text.shape[0]\n",
      "        print \"Number of features before feature selection \", len(vocab)\n",
      "        print \"Number of features after feature selection \", selected_features\n",
      "        print \"Sample distribution in train \", np.bincount(train_y)\n",
      "        print \"Class distribution in train \", np.bincount(train_y) / float(np.sum(np.bincount(train_y)))\n",
      "        print \"Sample distribution in test \", np.bincount(test_y)\n",
      "        print \"Class distribution in test \", np.bincount(test_y) / float(np.sum(np.bincount(test_y)))\n",
      "        \n",
      "        train_score = pipeline.score(train_text, train_y)\n",
      "        val_score = pipeline.score(test_text, test_y)\n",
      "        print \"Training and validation score \", train_score, val_score\n",
      "        \n",
      "        pred_y = pipeline.predict(test_text)\n",
      "        print \"Samples predicted in each class \", np.bincount(pred_y)\n",
      "        report = classification_report(test_y, pred_y)\n",
      "        print report\n",
      "        \n",
      "\n",
      "        pred_y_prob = pipeline.predict_proba(test_text)\n",
      "        \n",
      "        print pred_y.shape\n",
      "        print pred_y_prob.shape\n",
      "        \n",
      "        print test_y[0:10]\n",
      "        print test_y_binarize[0:10,:]\n",
      "        print pred_y[0:10]\n",
      "        print pred_y_prob[0:10,:]\n",
      "        plot_roc_curves(test_y_binarize[0:10,:], pred_y_prob[0:10,:])\n",
      "        \n",
      "        scores.append(val_score)\n",
      "        \n",
      "        break\n",
      "    score = sum(scores) / len(scores)\n",
      "    return score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Grid search with pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gridSearch(pipeline, parameters, X, y):\n",
      "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=3)\n",
      "\n",
      "    print(\"Performing grid search...\")\n",
      "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
      "    print(\"parameters:\")\n",
      "    pprint(parameters)\n",
      "    t0 = time()\n",
      "    grid_search.fit(X, y)\n",
      "    print(\"done in %0.3fs\" % (time() - t0))\n",
      "    print()\n",
      "\n",
      "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
      "    print(\"Best parameters set:\")\n",
      "    best_parameters = grid_search.best_estimator_.get_params()\n",
      "    for param_name in sorted(parameters.keys()):\n",
      "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def plot_roc_curves(y_test, y_score):\n",
      "    \n",
      "    n_classes = y_test.shape[1]\n",
      "    lw = 2\n",
      "    \n",
      "    fpr = dict()\n",
      "    tpr = dict()\n",
      "    roc_auc = dict()\n",
      "    \n",
      "    print y_test.shape\n",
      "    print y_score.shape\n",
      "    \n",
      "    for i in range(n_classes):\n",
      "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
      "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
      "\n",
      "    # Compute micro-average ROC curve and ROC area\n",
      "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
      "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
      "    print \"Micro Auc \",auc(fpr[\"micro\"], tpr[\"micro\"])\n",
      "    \n",
      "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
      "\n",
      "    # Then interpolate all ROC curves at this points\n",
      "    mean_tpr = np.zeros_like(all_fpr)\n",
      "    for i in range(n_classes):\n",
      "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
      "\n",
      "    # Finally average it and compute AUC\n",
      "    mean_tpr /= n_classes\n",
      "\n",
      "    fpr[\"macro\"] = all_fpr\n",
      "    tpr[\"macro\"] = mean_tpr\n",
      "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
      "    print \"Macro auc \",auc(fpr[\"macro\"], tpr[\"macro\"])\n",
      "    \n",
      "    # Plot all ROC curves\n",
      "    \"\"\"plt.figure()\n",
      "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
      "             label='micro-average ROC curve (area = {0:0.2f})'\n",
      "                   ''.format(roc_auc[\"micro\"]),\n",
      "             color='deeppink', linestyle=':', linewidth=4)\n",
      "\n",
      "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
      "             label='macro-average ROC curve (area = {0:0.2f})'\n",
      "                   ''.format(roc_auc[\"macro\"]),\n",
      "             color='navy', linestyle=':', linewidth=4)\n",
      "\n",
      "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'black'])\n",
      "    for i, color in zip(range(n_classes), colors):\n",
      "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
      "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
      "                 ''.format(i, roc_auc[i]))\n",
      "\n",
      "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.05])\n",
      "    plt.xlabel('False Positive Rate')\n",
      "    plt.ylabel('True Positive Rate')\n",
      "    plt.title('ROC analysis')\n",
      "    plt.legend(loc=\"lower right\")\n",
      "    plt.show()\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 147
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Various pipelines "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pipeline 1 : Unigram features, Count weights, SGD classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfIDFVect = TfidfVectorizer(ngram_range=(1,3), smooth_idf=1, use_idf=1, min_df=0.05, max_df=0.9, analyzer='word', sublinear_tf=1, stop_words=\"english\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countVect = CountVectorizer(ngram_range=(1,3), binary=True, min_df=0.05, max_df=0.9, analyzer='word', stop_words=\"english\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classifiers for feature selection "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = LogisticRegression(penalty='l1')\n",
      "lsvc = LinearSVC(penalty=\"l1\", dual=False)\n",
      "forest = ExtraTreesClassifier(n_estimators=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sfmLR = SelectFromModel(lr)\n",
      "sfmSVM = SelectFromModel(lsvc)\n",
      "sfmFR = SelectFromModel(forest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classifiers for prediction "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "svmClassifier = SVC(probability=True)\n",
      "naiveBayesClassifier = MultinomialNB()\n",
      "rfClassifier = RandomForestClassifier()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "xgb1 = XGBClassifier(\n",
      "        learning_rate =0.1,\n",
      "        n_estimators=100,\n",
      "        max_depth=5,\n",
      "        min_child_weight=5,\n",
      "        gamma=0.3,\n",
      "        subsample=0.8,\n",
      "        colsample_bytree=0.8,\n",
      "        objective= 'multi:softmax',\n",
      "        nthread=-1,\n",
      "        scale_pos_weight=1,\n",
      "        seed=27)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Count based pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Logistic Regression based feature selection\n",
      "count_LR_SVMpipeline = Pipeline([\n",
      "        ('vect', countVect),\n",
      "        ('f_select', sfmLR),\n",
      "        ('clf', svmClassifier)\n",
      "    ])\n",
      "\n",
      "count_LR_NBpipeline = Pipeline([\n",
      "        ('vect', countVect),\n",
      "        ('f_select', sfmLR),\n",
      "        ('clf', naiveBayesClassifier)\n",
      "    ])\n",
      "\n",
      "count_LR_RFpipeline = Pipeline([\n",
      "        ('vect', countVect),\n",
      "        ('f_select', sfmLR),\n",
      "        ('clf', rfClassifier)\n",
      "    ])\n",
      "\n",
      "count_LR_XGBpipeline = Pipeline([\n",
      "    ('vect', countVect),\n",
      "    ('f_select', sfmLR),\n",
      "    ('clf', xgb1),\n",
      "])\n",
      "\n",
      "#SVM based feature selection\n",
      "count_SVM_SVMpipeline = Pipeline([\n",
      "        ('vect', countVect),\n",
      "        ('f_select', sfmSVM),\n",
      "        ('clf', svmClassifier)\n",
      "    ])\n",
      "\n",
      "count_SVM_NBpipeline = Pipeline([\n",
      "        ('vect', countVect),\n",
      "        ('f_select', sfmSVM),\n",
      "        ('clf', naiveBayesClassifier)\n",
      "    ])\n",
      "\n",
      "count_SVM_RFpipeline = Pipeline([\n",
      "        ('vect', countVect),\n",
      "        ('f_select', sfmSVM),\n",
      "        ('clf', rfClassifier)\n",
      "    ])\n",
      "\n",
      "count_SVM_XGBpipeline = Pipeline([\n",
      "    ('vect', countVect),\n",
      "    ('f_select', sfmSVM),\n",
      "    ('clf', xgb1),\n",
      "])\n",
      "\n",
      "#Random Forest based feature selection\n",
      "count_RF_SVMpipeline = Pipeline([\n",
      "        ('vect', countVect),\n",
      "        ('f_select', sfmFR),\n",
      "        ('clf', svmClassifier)\n",
      "    ])\n",
      "\n",
      "count_RF_NBpipeline = Pipeline([\n",
      "        ('vect', countVect),\n",
      "        ('f_select', sfmFR),\n",
      "        ('clf', naiveBayesClassifier)\n",
      "    ])\n",
      "\n",
      "count_RF_RFpipeline = Pipeline([\n",
      "        ('vect', countVect),\n",
      "        ('f_select', sfmFR),\n",
      "        ('clf', rfClassifier)\n",
      "    ])\n",
      "\n",
      "count_RF_XGBpipeline = Pipeline([\n",
      "    ('vect', countVect),\n",
      "    ('f_select', sfmFR),\n",
      "    ('clf', xgb1),\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Tf-IDF based pipeline "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#Logistic Regression based feature selection\n",
      "tfidf_LR_SVMpipeline = Pipeline([\n",
      "        ('vect', tfIDFVect),\n",
      "        ('f_select', sfmLR),\n",
      "        ('clf', svmClassifier)\n",
      "    ])\n",
      "\n",
      "tfidf_LR_NBpipeline = Pipeline([\n",
      "        ('vect', tfIDFVect),\n",
      "        ('f_select', sfmLR),\n",
      "        ('clf', naiveBayesClassifier)\n",
      "    ])\n",
      "\n",
      "tfidf_LR_RFpipeline = Pipeline([\n",
      "        ('vect', tfIDFVect),\n",
      "        ('f_select', sfmLR),\n",
      "        ('clf', rfClassifier)\n",
      "    ])\n",
      "\n",
      "tfidf_LR_XGBpipeline = Pipeline([\n",
      "    ('vect', tfIDFVect),\n",
      "    ('f_select', sfmLR),\n",
      "    ('clf', xgb1),\n",
      "])\n",
      "\n",
      "#SVM based feature selection\n",
      "tfidf_SVM_SVMpipeline = Pipeline([\n",
      "        ('vect', tfIDFVect),\n",
      "        ('f_select', sfmSVM),\n",
      "        ('clf', svmClassifier)\n",
      "    ])\n",
      "\n",
      "tfidf_SVM_NBpipeline = Pipeline([\n",
      "        ('vect', tfIDFVect),\n",
      "        ('f_select', sfmSVM),\n",
      "        ('clf', naiveBayesClassifier)\n",
      "    ])\n",
      "\n",
      "tfidf_SVM_RFpipeline = Pipeline([\n",
      "        ('vect', tfIDFVect),\n",
      "        ('f_select', sfmSVM),\n",
      "        ('clf', rfClassifier)\n",
      "    ])\n",
      "\n",
      "tfidf_SVM_XGBpipeline = Pipeline([\n",
      "    ('vect', tfIDFVect),\n",
      "    ('f_select', sfmSVM),\n",
      "    ('clf', xgb1),\n",
      "])\n",
      "\n",
      "#Random Forest based feature selection\n",
      "tfidf_RF_SVMpipeline = Pipeline([\n",
      "        ('vect', tfIDFVect),\n",
      "        ('f_select', sfmFR),\n",
      "        ('clf', svmClassifier)\n",
      "    ])\n",
      "\n",
      "tfidf_RF_NBpipeline = Pipeline([\n",
      "        ('vect', tfIDFVect),\n",
      "        ('f_select', sfmFR),\n",
      "        ('clf', naiveBayesClassifier)\n",
      "    ])\n",
      "\n",
      "tfidf_RF_RFpipeline = Pipeline([\n",
      "        ('vect', tfIDFVect),\n",
      "        ('f_select', sfmFR),\n",
      "        ('clf', rfClassifier)\n",
      "    ])\n",
      "\n",
      "tfidf_RF_XGBpipeline = Pipeline([\n",
      "    ('vect', tfIDFVect),\n",
      "    ('f_select', sfmFR),\n",
      "    ('clf', xgb1),\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load data "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"../../data/train_corpus_labels_full_reports.pkl\", \"rb\") as filein:\n",
      "    train_corpus = pickle.load(filein)\n",
      "    labels = pickle.load(filein)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_corpus.shape\n",
      "print labels.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossValidation(5, count_LR_NBpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossValidation(5, count_LR_SVMpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossValidation(5, count_LR_RFpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossValidation(5, count_LR_XGBpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossValidation(5, count_RF_NBpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossValidation(5, count_RF_RFpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "crossValidation(5, count_RF_SVMpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossValidation(5, count_RF_XGBpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossValidation(5, count_SVM_NBpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossValidation(5, count_SVM_RFpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "crossValidation(5, count_SVM_SVMpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crossValidation(5, count_SVM_XGBpipeline, train_corpus, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "df_results = pd.read_excel(\"../../prelim_results.xlsx\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_results.groupby(\"Classifier\").mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_results.groupby(\"Classifier\").std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.barplot(x='Classifier', y='Accuracy', data=df_results)\n",
      "plt.title(\"Accuracy across classifiers\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.barplot(x='Classifier', y='Micro ROC', data=df_results)\n",
      "plt.title(\"Micro ROC across classifiers\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.barplot(x='Classifier', y='Macro ROC', data=df_results)\n",
      "plt.title(\"Macro ROC across classifiers\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
{
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import os\n",
      "import cPickle as pickle\n",
      "from pprint import pprint\n",
      "from time import time\n",
      "\n",
      "\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.metrics import classification_report, accuracy_score\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "\n",
      "import xgboost as xgb\n",
      "from xgboost.sklearn import XGBClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cross-validation with pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def crossValidation(n_folds, pipeline, X, y):\n",
      "    k_fold = StratifiedKFold(n_folds)\n",
      "    scores = []\n",
      "    for train_indices, test_indices in k_fold.split(X, y):\n",
      "        train_text = np.asarray(X[train_indices])\n",
      "        train_y    = np.asarray(y[train_indices])\n",
      "\n",
      "        test_text  = np.asarray(X[test_indices])\n",
      "        test_y     = np.asarray(y[test_indices])\n",
      "\n",
      "        pipeline.fit(train_text, train_y)\n",
      "        vocab = pipeline.named_steps[\"vect\"].vocabulary_\n",
      "        print len(vocab)\n",
      "        \n",
      "        print np.bincount(train_y) / float(np.sum(np.bincount(train_y)))\n",
      "        print np.bincount(test_y) / float(np.sum(np.bincount(test_y)))\n",
      "        train_score = pipeline.score(train_text, train_y)\n",
      "        val_score = pipeline.score(test_text, test_y)\n",
      "        print train_score, val_score\n",
      "        \n",
      "        pred_y = pipeline.predict(test_text)\n",
      "        print np.bincount(pred_y)\n",
      "        report = classification_report(test_y, pred_y)\n",
      "        print report\n",
      "        \n",
      "        scores.append(val_score)\n",
      "\n",
      "    score = sum(scores) / len(scores)\n",
      "    return score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Grid search with pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gridSearch(pipeline, parameters, X, y):\n",
      "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=3)\n",
      "\n",
      "    print(\"Performing grid search...\")\n",
      "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
      "    print(\"parameters:\")\n",
      "    pprint(parameters)\n",
      "    t0 = time()\n",
      "    grid_search.fit(X, y)\n",
      "    print(\"done in %0.3fs\" % (time() - t0))\n",
      "    print()\n",
      "\n",
      "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
      "    print(\"Best parameters set:\")\n",
      "    best_parameters = grid_search.best_estimator_.get_params()\n",
      "    for param_name in sorted(parameters.keys()):\n",
      "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Various pipelines "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pipeline 1 : Unigram features, Count weights, SGD classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfIDFVect = TfidfVectorizer(ngram_range=(1,3), smooth_idf=1, use_idf=1, min_df=0.05, max_df=0.9, analyzer='word', sublinear_tf=1, stop_words=\"english\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countVect = CountVectorizer(ngram_range=(1,3), binary=True, min_df=0.05, max_df=0.9, analyzer='word', stop_words=\"english\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "pca = TruncatedSVD(n_components=600)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lrClassifier = LogisticRegression(penalty='l1')\n",
      "svmClassifier = SVC()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "xgb1 = XGBClassifier(\n",
      "        learning_rate =0.1,\n",
      "        n_estimators=100,\n",
      "        max_depth=5,\n",
      "        min_child_weight=5,\n",
      "        gamma=0.3,\n",
      "        subsample=0.8,\n",
      "        colsample_bytree=0.8,\n",
      "        objective= 'multi:softmax',\n",
      "        nthread=-1,\n",
      "        scale_pos_weight=1,\n",
      "        seed=27)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countLRpipeline = Pipeline([\n",
      "        ('vect', countVect),\n",
      "        ('pca', pca),\n",
      "        ('clf', lrClassifier)\n",
      "    ])\n",
      "\n",
      "tfIdfLRpipeline = Pipeline([\n",
      "    ('vect', tfIDFVect),\n",
      "    ('pca', pca),\n",
      "    ('clf', lrClassifier),\n",
      "])\n",
      "\n",
      "countXGBpipeline = Pipeline([\n",
      "    ('vect', countVect),\n",
      "    #('pca', pca),\n",
      "    ('clf', xgb1),\n",
      "])\n",
      "\n",
      "tfIdfXGBpipeline = Pipeline([\n",
      "    ('vect', tfIDFVect),\n",
      "    #('pca', pca),\n",
      "    ('clf', xgb1),\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"../../data/train_corpus_labels_full_reports.pkl\", \"rb\") as filein:\n",
      "    train_corpus = pickle.load(filein)\n",
      "    labels = pickle.load(filein)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_corpus.shape\n",
      "print labels.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countVect.fit(train_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "train_corpus_count = countVect.transform(train_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(countVect.vocabulary_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_selection import SelectFromModel\n",
      "sfmLR = SelectFromModel(lrClassifier)\n",
      "sfmLR.fit(train_corpus_count, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "train_corpus_count_selFeature = sfmLR.transform(train_corpus_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}